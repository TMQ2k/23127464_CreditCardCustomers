{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c87c585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from data_processing import *\n",
    "np.set_printoptions(suppress=True, precision=4, linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d899c",
   "metadata": {},
   "source": [
    "# **1. Khởi tạo và Đọc dữ liệu**\n",
    "* **Xử lý sơ bộ:** Loại bỏ header và 2 cột cuối cùng (Naive Bayes Classifiers) không cần thiết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "757b4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu: (10127, 21)\n",
      "Danh sách Features: ['CLIENTNUM', 'Attrition_Flag', 'Customer_Age', 'Gender', 'Dependent_count', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/raw/BankChurners.csv\"\n",
    "\n",
    "# 1. Đọc header để lấy tên cột\n",
    "with open(file_path, \"r\") as f:\n",
    "    header_line = f.readline().strip()\n",
    "    raw_names = [c.strip('\"') for c in header_line.split(\",\")]\n",
    "    col_names = raw_names[:-2]\n",
    "\n",
    "data_raw = np.genfromtxt(\n",
    "    file_path, \n",
    "    delimiter=\",\", \n",
    "    dtype=str, \n",
    "    skip_header=1\n",
    ")\n",
    "\n",
    "data = data_raw[:, :-2]\n",
    "data = np.char.strip(np.char.strip(data, '\"'))\n",
    "\n",
    "print(\"Kích thước dữ liệu:\", data.shape)\n",
    "print(\"Danh sách Features:\", col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b7a85",
   "metadata": {},
   "source": [
    "# **2. Kiểm tra tính hợp lệ của dữ liệu (Data Validation)**\n",
    "Trước khi xử lý, cần kiểm tra:\n",
    "* **Data Types:** Đảm bảo các cột numerical thực sự là số\n",
    "* **Range Validation:** Kiểm tra giá trị trong phạm vi hợp lệ\n",
    "* **Duplicates:** Phát hiện dòng trùng lặp\n",
    "* **Consistency:** Kiểm tra tính nhất quán của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50f9c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIỂM TRA TÍNH HỢP LỆ CỦA DỮ LIỆU\n",
      "\n",
      "1. Duplicates: 0 dòng trùng lặp\n",
      "\n",
      "2. Validation Rules cho Numerical Columns:\n",
      "Column                         Min          Max          Valid Range          Status\n",
      "------------------------------------------------------------------------------------------\n",
      "Customer_Age                   26.00        73.00        [18, 120]            OK\n",
      "Dependent_count                0.00         5.00         (-inf, +inf)         OK\n",
      "Months_on_book                 13.00        56.00        (-inf, +inf)         OK\n",
      "Total_Relationship_Count       1.00         6.00         (-inf, +inf)         OK\n",
      "Months_Inactive_12_mon         0.00         6.00         [0, 12]              OK\n",
      "Contacts_Count_12_mon          0.00         6.00         (-inf, +inf)         OK\n",
      "Credit_Limit                   1438.30      34516.00     [0, +inf)            OK\n",
      "Total_Revolving_Bal            0.00         2517.00      [0, +inf)            OK\n",
      "Avg_Open_To_Buy                3.00         34516.00     (-inf, +inf)         OK\n",
      "Total_Amt_Chng_Q4_Q1           0.00         3.40         (-inf, +inf)         OK\n",
      "Total_Trans_Amt                510.00       18484.00     [0, +inf)            OK\n",
      "Total_Trans_Ct                 10.00        139.00       [0, +inf)            OK\n",
      "Total_Ct_Chng_Q4_Q1            0.00         3.71         (-inf, +inf)         OK\n",
      "Avg_Utilization_Ratio          0.00         1.00         [0, 1]               OK\n",
      "\n",
      "3. Data Type Consistency:\n",
      "  Customer_Age                   Có thể convert sang float\n",
      "  Dependent_count                Có thể convert sang float\n",
      "  Months_on_book                 Có thể convert sang float\n",
      "  Total_Relationship_Count       Có thể convert sang float\n",
      "  Months_Inactive_12_mon         Có thể convert sang float\n"
     ]
    }
   ],
   "source": [
    "print(\"KIỂM TRA TÍNH HỢP LỆ CỦA DỮ LIỆU\")\n",
    " \n",
    "# 1. Kiểm tra Duplicates\n",
    "clientnum_idx = col_names.index(\"CLIENTNUM\")\n",
    "unique_clients = np.unique(data[:, clientnum_idx])\n",
    "n_duplicates = len(data) - len(unique_clients)\n",
    "print(f\"\\n1. Duplicates: {n_duplicates} dòng trùng lặp\")\n",
    "\n",
    "# 2. Định nghĩa các cột numerical sử dụng từ dataset\n",
    "numerical_cols , _ = feature_typing(col_names , data)\n",
    "numerical_cols = numerical_cols[1:]\n",
    "\n",
    "# 3. Validation Rules\n",
    "print(\"\\n2. Validation Rules cho Numerical Columns:\")\n",
    "print(f\"{'Column':<30} {'Min':<12} {'Max':<12} {'Valid Range':<20} {'Status'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "validation_results = []\n",
    "for col in numerical_cols:\n",
    "    if col in col_names:\n",
    "        idx = col_names.index(col)\n",
    "        col_data = data[:, idx].astype(float)\n",
    "        \n",
    "        actual_min = np.min(col_data)\n",
    "        actual_max = np.max(col_data)\n",
    "        \n",
    "        # Business logic constraints\n",
    "        if col == \"Avg_Utilization_Ratio\":\n",
    "            valid_min, valid_max = 0, 1\n",
    "            constraint = \"[0, 1]\"\n",
    "        elif col == \"Customer_Age\":\n",
    "            valid_min, valid_max = 18, 120\n",
    "            constraint = \"[18, 120]\"\n",
    "        elif col in [\"Months_Inactive_12_mon\"]:\n",
    "            valid_min, valid_max = 0, 12\n",
    "            constraint = \"[0, 12]\"\n",
    "        elif col in [\"Credit_Limit\", \"Total_Revolving_Bal\", \"Total_Trans_Amt\", \"Total_Trans_Ct\"]:\n",
    "            valid_min, valid_max = 0, np.inf\n",
    "            constraint = \"[0, +inf)\"\n",
    "        else:\n",
    "            valid_min, valid_max = -np.inf, np.inf\n",
    "            constraint = \"(-inf, +inf)\"\n",
    "        \n",
    "        # Check violations\n",
    "        violations = np.sum((col_data < valid_min) | (col_data > valid_max))\n",
    "        status = \"OK\" if violations == 0 else f\"{violations} vi phạm\"\n",
    "        \n",
    "        validation_results.append({\n",
    "            'column': col,\n",
    "            'violations': violations,\n",
    "            'actual_min': actual_min,\n",
    "            'actual_max': actual_max\n",
    "        })\n",
    "        \n",
    "        print(f\"{col:<30} {actual_min:<12.2f} {actual_max:<12.2f} {constraint:<20} {status}\")\n",
    "\n",
    "# 4. Kiểm tra data type consistency\n",
    "print(\"\\n3. Data Type Consistency:\")\n",
    "for col in numerical_cols[:5]:  # Check first 5\n",
    "    idx = col_names.index(col)\n",
    "    try:\n",
    "        _ = data[:, idx].astype(float)\n",
    "        print(f\"  {col:<30} Có thể convert sang float\")\n",
    "    except ValueError as e:\n",
    "        print(f\"  {col:<30} Lỗi: {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555ceff",
   "metadata": {},
   "source": [
    "# **3. Xử lý Missing Values**\n",
    "Xác định và xử lý các giá trị bị thiếu hoặc giá trị rác (`Unknown`).\n",
    "* **Chiến lược cho biến phân loại (Categorical):** Thay thế `Unknown` bằng **Mode** (giá trị xuất hiện nhiều nhất trong cột đó).\n",
    "* **Chiến lược cho biến số (Numerical):** Nếu có `NaN`, thay thế bằng **Mean** hoặc **Median**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fad4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý Missing Values (Categorical)\n",
      "\n",
      "Cột Attrition_Flag      : Không có giá trị missing.\n",
      "Cột Gender              : Không có giá trị missing.\n",
      "Cột Education_Level     : Đã thay thế 1519 dòng 'Unknown' => Mode: 'Graduate'\n",
      "Cột Marital_Status      : Đã thay thế  749 dòng 'Unknown' => Mode: 'Married'\n",
      "Cột Income_Category     : Đã thay thế 1112 dòng 'Unknown' => Mode: 'Less than $40K'\n",
      "Cột Card_Category       : Không có giá trị missing.\n"
     ]
    }
   ],
   "source": [
    "missing_token = \"Unknown\"\n",
    "\n",
    "# Xử lý Missing Values cho các cột Categorical\n",
    "_ , categorical_cols_to_fix = feature_typing(col_names , data)\n",
    "print(\"Xử lý Missing Values (Categorical)\\n\")\n",
    "\n",
    "for name in categorical_cols_to_fix:\n",
    "    if name in col_names:\n",
    "        idx = col_names.index(name)\n",
    "        col_data = data[:, idx]\n",
    "        \n",
    "        # Xác định vị trí missing\n",
    "        mask_missing = (col_data == missing_token)\n",
    "        count_missing = np.sum(mask_missing)\n",
    "        \n",
    "        if count_missing > 0:\n",
    "            # Tính Mode trên dữ liệu sạch (không chứa Unknown)\n",
    "            valid_data = col_data[~mask_missing]\n",
    "            vals, counts = np.unique(valid_data, return_counts=True)\n",
    "            mode_val = vals[np.argmax(counts)]\n",
    "            \n",
    "            # Thay thế Unknown bằng Mode\n",
    "            data[:, idx] = np.where(mask_missing, mode_val, col_data)\n",
    "            \n",
    "            print(f\"Cột {name:20s}: Đã thay thế {count_missing:4d} dòng '{missing_token}' => Mode: '{mode_val}'\")\n",
    "        else:\n",
    "            print(f\"Cột {name:20s}: Không có giá trị missing.\")\n",
    "\n",
    "idx_cl = col_names.index(\"Credit_Limit\")\n",
    "col_cl = data[:, idx_cl]\n",
    "\n",
    "# Xử lý Missing Values cho cột Credit_Limit (Numeric)\n",
    "try:\n",
    "    col_float = col_cl.astype(float)\n",
    "    if np.isnan(col_float).any():\n",
    "        mean_val = np.nanmean(col_float)\n",
    "        mask_nan = np.isnan(col_float)\n",
    "        data[mask_nan, idx_cl] = str(mean_val)\n",
    "        print(\"Đã xử lý NaN cho Credit_Limit\")\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffabc3",
   "metadata": {},
   "source": [
    "# **4. Feature Engineering (Tạo đặc trưng mới)**\n",
    "Tạo thêm các biến mới để hỗ trợ mô hình học máy tốt hơn:\n",
    "1.  **Avg_Transaction_Value**: Giá trị trung bình mỗi giao dịch ($Total\\_Trans\\_Amt / Total\\_Trans\\_Ct$).\n",
    "2.  **Utilization_Ratio**: Tỷ lệ sử dụng hạn mức tín dụng ($Total\\_Revolving\\_Bal / Credit\\_Limit$).\n",
    "\n",
    "Các phép tính số học được thực hiện cẩn thận để tránh lỗi chia cho 0 (ZeroDivisionError)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aada6b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu sau khi thêm Features: (10127, 23)\n",
      "Features mới: ['Avg_Transaction_Value', 'Utilization_Ratio']\n"
     ]
    }
   ],
   "source": [
    "# Lấy index các cột cần dùng\n",
    "idx_amt = col_names.index(\"Total_Trans_Amt\")\n",
    "idx_ct  = col_names.index(\"Total_Trans_Ct\")\n",
    "idx_bal = col_names.index(\"Total_Revolving_Bal\")\n",
    "idx_lim = col_names.index(\"Credit_Limit\")\n",
    "\n",
    "# Chuyển đổi dữ liệu sang dạng số (float) để tính toán\n",
    "amt = data[:, idx_amt].astype(float)\n",
    "ct  = data[:, idx_ct].astype(float)\n",
    "bal = data[:, idx_bal].astype(float)\n",
    "lim = data[:, idx_lim].astype(float)\n",
    "\n",
    "# 1. Feature: Average Transaction Value\n",
    "# Sử dụng np.maximum(ct, 1) để đảm bảo mẫu số tối thiểu là 1, tránh chia cho 0\n",
    "avg_trans_val = amt / np.maximum(ct, 1)\n",
    "\n",
    "# 2. Feature: Utilization Ratio\n",
    "util_ratio = bal / np.maximum(lim, 1)\n",
    "\n",
    "# Ghép các feature mới vào dataset\n",
    "avg_trans_val_str = np.char.mod('%.4f', avg_trans_val)\n",
    "util_ratio_str = np.char.mod('%.4f', util_ratio)\n",
    "\n",
    "# Reshape để ghép cột\n",
    "new_features = np.column_stack((avg_trans_val_str, util_ratio_str))\n",
    "data = np.hstack((data, new_features))\n",
    "\n",
    "# Cập nhật danh sách tên cột\n",
    "col_names.extend([\"Avg_Transaction_Value\", \"Utilization_Ratio\"])\n",
    "\n",
    "print(\"Kích thước dữ liệu sau khi thêm Features:\", data.shape)\n",
    "print(\"Features mới:\", col_names[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d6f6c",
   "metadata": {},
   "source": [
    "# **5. Feature Engineering - Tạo thêm features từ domain knowledge**\n",
    "Dựa trên hiểu biết về business banking, tạo thêm các features có ý nghĩa:\n",
    "1. **Transaction_Frequency:** Tần suất giao dịch trung bình (transactions/month)\n",
    "2. **Inactive_Ratio:** Tỷ lệ thời gian không hoạt động\n",
    "3. **Credit_Usage_Category:** Phân loại mức độ sử dụng tín dụng\n",
    "4. **Customer_Lifetime_Value (CLV):** Ước lượng giá trị khách hàng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d81802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ENGINEERING - TẠO THÊM FEATURES MỚI\n",
      "\n",
      "Đã tạo 4 engineered features:\n",
      "   1. Transaction_Frequency\n",
      "   2. Inactive_Ratio\n",
      "   3. Customer_Lifetime_Value\n",
      "   4. Engagement_Score\n",
      "\n",
      "Kích thước dữ liệu sau Feature Engineering: (10127, 27)\n",
      "Tổng số features: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"FEATURE ENGINEERING - TẠO THÊM FEATURES MỚI\")\n",
    "\n",
    "# Lấy các columns cần thiết\n",
    "idx_months = col_names.index(\"Months_on_book\")\n",
    "idx_inactive = col_names.index(\"Months_Inactive_12_mon\")\n",
    "idx_trans_ct = col_names.index(\"Total_Trans_Ct\")\n",
    "idx_trans_amt = col_names.index(\"Total_Trans_Amt\")\n",
    "idx_rel_count = col_names.index(\"Total_Relationship_Count\")\n",
    "\n",
    "months_on_book = data[:, idx_months].astype(float)\n",
    "months_inactive = data[:, idx_inactive].astype(float)\n",
    "trans_ct = data[:, idx_trans_ct].astype(float)\n",
    "trans_amt = data[:, idx_trans_amt].astype(float)\n",
    "rel_count = data[:, idx_rel_count].astype(float)\n",
    "\n",
    "# Feature 3: Transaction Frequency (transactions per month)\n",
    "trans_frequency = trans_ct / np.maximum(months_on_book, 1)\n",
    "\n",
    "# Feature 4: Inactive Ratio\n",
    "inactive_ratio = months_inactive / 12.0  # Tỷ lệ inactive trong 12 tháng\n",
    "\n",
    "# Feature 5: Customer Lifetime Value (CLV) estimate\n",
    "# CLV = Avg Transaction Amount * Transaction Frequency * Months on Book * Relationship Count\n",
    "clv = (trans_amt / np.maximum(trans_ct, 1)) * trans_frequency * months_on_book * rel_count\n",
    "\n",
    "# Feature 6: Engagement Score (composite)\n",
    "# Engagement = (1 - inactive_ratio) * transaction_frequency * relationship_count\n",
    "engagement_score = (1 - inactive_ratio) * trans_frequency * rel_count\n",
    "\n",
    "# Thêm vào dataset\n",
    "new_features_2 = np.column_stack([\n",
    "    np.char.mod('%.6f', trans_frequency),\n",
    "    np.char.mod('%.6f', inactive_ratio),\n",
    "    np.char.mod('%.6f', clv),\n",
    "    np.char.mod('%.6f', engagement_score)\n",
    "])\n",
    "\n",
    "data = np.hstack((data, new_features_2))\n",
    "\n",
    "new_feature_names = [\n",
    "    \"Transaction_Frequency\",\n",
    "    \"Inactive_Ratio\", \n",
    "    \"Customer_Lifetime_Value\",\n",
    "    \"Engagement_Score\"\n",
    "]\n",
    "\n",
    "col_names.extend(new_feature_names)\n",
    "\n",
    "print(f\"\\nĐã tạo {len(new_feature_names)} engineered features:\")\n",
    "for i, fname in enumerate(new_feature_names):\n",
    "    print(f\"   {i+1}. {fname}\")\n",
    "\n",
    "print(f\"\\nKích thước dữ liệu sau Feature Engineering: {data.shape}\")\n",
    "print(f\"Tổng số features: {len(col_names)}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ca5c4",
   "metadata": {},
   "source": [
    "# **6. Xử lý Outliers (Giá trị ngoại lai)**\n",
    "Sử dụng phương pháp **Z-Score** để phát hiện và xử lý ngoại lai cho các biến số.\n",
    "Công thức Z-score:\n",
    "$$Z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "* **Ngưỡng:** $|Z| > 3$.\n",
    "* **Phương pháp xử lý:** **Capping (Winsorizing)** - Thay thế giá trị vượt ngưỡng bằng giá trị biên (Mean $\\pm$ 3*Std) thay vì xóa bỏ dòng dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5771e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý Outliers\n",
      "Credit_Limit             : Đã xử lý    0 outliers (Capping)\n",
      "Total_Trans_Amt          : Đã xử lý  391 outliers (Capping)\n",
      "Avg_Transaction_Value    : Đã xử lý  244 outliers (Capping)\n"
     ]
    }
   ],
   "source": [
    "def cap_outliers_zscore(values):\n",
    "    \n",
    "    values = values.astype(float)\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    \n",
    "    if std == 0: return values, 0\n",
    "    \n",
    "    threshold = 3\n",
    "    upper_bound = mean + threshold * std\n",
    "    lower_bound = mean - threshold * std\n",
    "    \n",
    "    # Đếm outliers\n",
    "    n_outliers = np.sum((values > upper_bound) | (values < lower_bound))\n",
    "    \n",
    "    # Capping (Kẹp giá trị trong khoảng)\n",
    "    values_clipped = np.clip(values, lower_bound, upper_bound)\n",
    "    \n",
    "    return values_clipped, n_outliers\n",
    "\n",
    "# Áp dụng cho một số biến số quan trọng\n",
    "numeric_cols_to_clean = [\"Credit_Limit\", \"Total_Trans_Amt\", \"Avg_Transaction_Value\"]\n",
    "\n",
    "print(\"Xử lý Outliers\")\n",
    "for name in numeric_cols_to_clean:\n",
    "    idx = col_names.index(name)\n",
    "    col_vals = data[:, idx]\n",
    "    \n",
    "    # Xử lý\n",
    "    cleaned_vals, n_out = cap_outliers_zscore(col_vals)\n",
    "    \n",
    "    # Cập nhật lại vào data (ép về dạng string)\n",
    "    data[:, idx] = np.char.mod('%.4f', cleaned_vals)\n",
    "    \n",
    "    print(f\"{name:25s}: Đã xử lý {n_out:4d} outliers (Capping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4a1e1",
   "metadata": {},
   "source": [
    "# **7. Phương pháp IQR (Interquartile Range) để phát hiện Outliers**\n",
    "Phương pháp IQR là một cách robust hơn Z-score, không bị ảnh hưởng bởi outliers cực đoan.\n",
    "\n",
    "**Công thức:**\n",
    "* $IQR = Q_3 - Q_1$\n",
    "* **Lower Bound:** $Q_1 - 1.5 \\times IQR$\n",
    "* **Upper Bound:** $Q_3 + 1.5 \\times IQR$\n",
    "\n",
    "**So sánh:** IQR vs Z-Score để quyết định có nên loại bỏ outliers không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f397e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO SÁNH PHƯƠNG PHÁP PHÁT HIỆN OUTLIERS: Z-SCORE vs IQR\n",
      "\n",
      "Cột phân tích: Total_Trans_Amt\n",
      "Tổng số samples: 10127\n",
      "\n",
      "1. Z-Score Method (threshold=3):\n",
      "   Outliers detected: 504 (4.98%)\n",
      "   Bounds: Mean ± 3*Std = [-5477.23, 14215.23]\n",
      "\n",
      "2. IQR Method (multiplier=1.5):\n",
      "   Q1 = 2155.50, Q3 = 4741.00, IQR = 2585.50\n",
      "   Outliers detected: 896 (8.85%)\n",
      "   Bounds: [-1722.75, 8619.25]\n",
      "\n",
      "Phân tích và Quyết định:\n",
      "   Tỷ lệ outliers 5-10% -> NÊN CAPPING thay vì xóa\n",
      "\n",
      "Kết luận:\n",
      "   Trong trường hợp này, ta sử dụng CAPPING (đã thực hiện ở bước 4)\n",
      "   Lý do: Giữ lại toàn bộ samples, tránh mất thông tin quan trọng\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers_iqr(values, multiplier=1.5):\n",
    "\n",
    "    values = values.astype(float)\n",
    "    q1 = np.percentile(values, 25)\n",
    "    q3 = np.percentile(values, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    lower_bound = q1 - multiplier * iqr\n",
    "    upper_bound = q3 + multiplier * iqr\n",
    "    \n",
    "    outliers = (values < lower_bound) | (values > upper_bound)\n",
    "    n_outliers = np.sum(outliers)\n",
    "    \n",
    "    return {\n",
    "        'q1': q1,\n",
    "        'q3': q3,\n",
    "        'iqr': iqr,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'n_outliers': n_outliers,\n",
    "        'outlier_pct': (n_outliers / len(values)) * 100\n",
    "    }\n",
    "\n",
    "\n",
    "# So sánh Z-Score vs IQR \n",
    "print(\"SO SÁNH PHƯƠNG PHÁP PHÁT HIỆN OUTLIERS: Z-SCORE vs IQR\")\n",
    " \n",
    "\n",
    "test_col = \"Total_Trans_Amt\"\n",
    "idx_test = col_names.index(test_col)\n",
    "test_values = data[:, idx_test].astype(float)\n",
    "\n",
    "# Phương pháp 1: Z-Score\n",
    "mean_val = np.mean(test_values)\n",
    "std_val = np.std(test_values)\n",
    "z_scores = np.abs((test_values - mean_val) / std_val)\n",
    "outliers_zscore = z_scores > 3\n",
    "n_outliers_zscore = np.sum(outliers_zscore)\n",
    "\n",
    "# Phương pháp 2: IQR\n",
    "iqr_result = detect_outliers_iqr(test_values, multiplier=1.5)\n",
    "\n",
    "print(f\"\\nCột phân tích: {test_col}\")\n",
    "print(f\"Tổng số samples: {len(test_values)}\")\n",
    "print(\"\\n1. Z-Score Method (threshold=3):\")\n",
    "print(f\"   Outliers detected: {n_outliers_zscore} ({n_outliers_zscore/len(test_values)*100:.2f}%)\")\n",
    "print(f\"   Bounds: Mean ± 3*Std = [{mean_val - 3*std_val:.2f}, {mean_val + 3*std_val:.2f}]\")\n",
    "\n",
    "print(\"\\n2. IQR Method (multiplier=1.5):\")\n",
    "print(f\"   Q1 = {iqr_result['q1']:.2f}, Q3 = {iqr_result['q3']:.2f}, IQR = {iqr_result['iqr']:.2f}\")\n",
    "print(f\"   Outliers detected: {iqr_result['n_outliers']} ({iqr_result['outlier_pct']:.2f}%)\")\n",
    "print(f\"   Bounds: [{iqr_result['lower_bound']:.2f}, {iqr_result['upper_bound']:.2f}]\")\n",
    "\n",
    "print(\"\\nPhân tích và Quyết định:\")\n",
    "if iqr_result['outlier_pct'] < 5:\n",
    "    print(\"   Tỷ lệ outliers < 5% -> CÓ THỂ XÓA BỎ nếu cần\")\n",
    "    print(\"   NHƯNG: Nên dùng CAPPING/WINSORIZING để giữ lại thông tin\")\n",
    "elif iqr_result['outlier_pct'] < 10:\n",
    "    print(\"   Tỷ lệ outliers 5-10% -> NÊN CAPPING thay vì xóa\")\n",
    "else:\n",
    "    print(\"   Tỷ lệ outliers > 10% -> KHÔNG NÊN XÓA, dùng Robust methods\")\n",
    "\n",
    "print(\"\\nKết luận:\")\n",
    "print(\"   Trong trường hợp này, ta sử dụng CAPPING (đã thực hiện ở bước 4)\")\n",
    "print(\"   Lý do: Giữ lại toàn bộ samples, tránh mất thông tin quan trọng\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b603b59",
   "metadata": {},
   "source": [
    "# **8. Chuẩn hóa và Điều chuẩn dữ liệu**\n",
    "Thực hiện các kỹ thuật scaling thủ công:\n",
    "1.  **Min-Max Scaling:** Đưa dữ liệu về đoạn $[0, 1]$.\n",
    "    $$X_{norm} = \\frac{X - min}{max - min}$$\n",
    "2.  **Standardization (Z-score Scaling):** Đưa dữ liệu về phân phối chuẩn ($\\mu=0, \\sigma=1$).\n",
    "    $$X_{std} = \\frac{X - \\mu}{\\sigma}$$\n",
    "3.  **Log Transformation:** Giảm độ lệch (skewness).\n",
    "    $$X_{log} = \\ln(X + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d849e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biến đổi đặc trưng: Total_Trans_Amt\n",
      "Index | Original   | MinMax     | Standard   | Log       \n",
      "-------------------------------------------------------\n",
      "0     | 1144.00    | 0.0450     | -0.9826    | 7.0432    \n",
      "1     | 1291.00    | 0.0554     | -0.9378    | 7.1639    \n",
      "2     | 1887.00    | 0.0978     | -0.7562    | 7.5433    \n",
      "3     | 1171.00    | 0.0469     | -0.9744    | 7.0665    \n",
      "4     | 816.00     | 0.0217     | -1.0825    | 6.7056    \n",
      "\n",
      "Kiểm tra Standardization -> Mean: -0.00000 (approx 0), Std: 1.00000 (approx 1)\n"
     ]
    }
   ],
   "source": [
    "idx_target = col_names.index(\"Total_Trans_Amt\")\n",
    "raw_feature = data[:, idx_target].astype(float)\n",
    "\n",
    "feat_minmax = min_max_scale(raw_feature)\n",
    "feat_std = standard_scale(raw_feature)\n",
    "feat_log = log_transform(raw_feature)\n",
    "\n",
    "print(f\"Biến đổi đặc trưng: {col_names[idx_target]}\")\n",
    "print(f\"{'Index':<5} | {'Original':<10} | {'MinMax':<10} | {'Standard':<10} | {'Log':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(5):\n",
    "    print(f\"{i:<5} | {raw_feature[i]:<10.2f} | {feat_minmax[i]:<10.4f} | {feat_std[i]:<10.4f} | {feat_log[i]:<10.4f}\")\n",
    "\n",
    "print(f\"\\nKiểm tra Standardization -> Mean: {np.mean(feat_std):.5f} (approx 0), Std: {np.std(feat_std):.5f} (approx 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29a879",
   "metadata": {},
   "source": [
    "# **9. Áp dụng Scaling cho toàn bộ Numerical Features**\n",
    "Chiến lược scaling dựa trên distribution của từng feature:\n",
    "* **Standardization (Z-score):** Cho features có phân phối gần Gaussian\n",
    "* **Min-Max:** Cho features có distribution uniform hoặc bounded\n",
    "* **Log Transform:** Cho features có skewness cao (right-skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d04835e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÁP DỤNG SCALING CHO NUMERICAL FEATURES\n",
      "\n",
      "Phân tích Distribution và chọn Scaling Method:\n",
      "Column                         Skewness     Method              \n",
      "-----------------------------------------------------------------\n",
      "\n",
      "Phân tích Distribution và chọn Scaling Method:\n",
      "Column                         Skewness     Method              \n",
      "-----------------------------------------------------------------\n",
      "Customer_Age                   -0.034       Standardization     \n",
      "Customer_Age                   -0.034       Standardization     \n",
      "Dependent_count                -0.021       Standardization     \n",
      "Months_on_book                 -0.107       Standardization     \n",
      "Total_Relationship_Count       -0.162       Standardization     \n",
      "Dependent_count                -0.021       Standardization     \n",
      "Months_on_book                 -0.107       Standardization     \n",
      "Total_Relationship_Count       -0.162       Standardization     \n",
      "Months_Inactive_12_mon         0.633        Min-Max             \n",
      "Contacts_Count_12_mon          0.011        Standardization     \n",
      "Credit_Limit                   1.667        Log + Standardization\n",
      "Total_Revolving_Bal            -0.149       Standardization     \n",
      "Avg_Open_To_Buy                1.662        Log + Standardization\n",
      "Months_Inactive_12_mon         0.633        Min-Max             \n",
      "Contacts_Count_12_mon          0.011        Standardization     \n",
      "Credit_Limit                   1.667        Log + Standardization\n",
      "Total_Revolving_Bal            -0.149       Standardization     \n",
      "Avg_Open_To_Buy                1.662        Log + Standardization\n",
      "Total_Amt_Chng_Q4_Q1           1.732        Log + Standardization\n",
      "Total_Trans_Amt                1.939        Log + Standardization\n",
      "Total_Trans_Ct                 0.154        Standardization     \n",
      "Total_Ct_Chng_Q4_Q1            2.064        Log + Standardization\n",
      "Avg_Utilization_Ratio          0.718        Min-Max             \n",
      "Avg_Transaction_Value          1.746        Log + Standardization\n",
      "Utilization_Ratio              0.718        Min-Max             \n",
      "Transaction_Frequency          1.442        Log + Standardization\n",
      "Inactive_Ratio                 0.633        Min-Max             \n",
      "Customer_Lifetime_Value        2.497        Log + Standardization\n",
      "Engagement_Score               1.414        Log + Standardization\n",
      "Total_Amt_Chng_Q4_Q1           1.732        Log + Standardization\n",
      "Total_Trans_Amt                1.939        Log + Standardization\n",
      "Total_Trans_Ct                 0.154        Standardization     \n",
      "Total_Ct_Chng_Q4_Q1            2.064        Log + Standardization\n",
      "Avg_Utilization_Ratio          0.718        Min-Max             \n",
      "Avg_Transaction_Value          1.746        Log + Standardization\n",
      "Utilization_Ratio              0.718        Min-Max             \n",
      "Transaction_Frequency          1.442        Log + Standardization\n",
      "Inactive_Ratio                 0.633        Min-Max             \n",
      "Customer_Lifetime_Value        2.497        Log + Standardization\n",
      "Engagement_Score               1.414        Log + Standardization\n"
     ]
    }
   ],
   "source": [
    "def calculate_skewness(arr):\n",
    "    arr = arr.astype(float)\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    if std == 0: return 0\n",
    "    n = len(arr)\n",
    "    return (n / ((n-1) * (n-2))) * np.sum(((arr - mean) / std) ** 3)\n",
    "\n",
    " \n",
    "print(\"ÁP DỤNG SCALING CHO NUMERICAL FEATURES\")\n",
    " \n",
    "\n",
    "# Tạo dict để lưu scaled data\n",
    "scaled_data = data.copy()\n",
    "\n",
    "# Xác định numerical columns để scale\n",
    "numerical_cols_to_scale , _ = feature_typing(col_names , data)\n",
    "numerical_cols_to_scale = numerical_cols_to_scale[1:]\n",
    "\n",
    "print(f\"\\nPhân tích Distribution và chọn Scaling Method:\")\n",
    "print(f\"{'Column':<30} {'Skewness':<12} {'Method':<20}\")\n",
    "print(\"-\"*65)\n",
    "\n",
    "scaling_methods = {}\n",
    "\n",
    "for col in numerical_cols_to_scale:\n",
    "    if col in col_names:\n",
    "        idx = col_names.index(col)\n",
    "        col_data = data[:, idx].astype(float)\n",
    "        \n",
    "        # Tính skewness\n",
    "        skew = calculate_skewness(col_data)\n",
    "        \n",
    "        # Quyết định method dựa trên skewness\n",
    "        if abs(skew) < 0.5:\n",
    "            method = \"Standardization\"\n",
    "            scaled = standard_scale(col_data)\n",
    "        elif abs(skew) < 1.0:\n",
    "            method = \"Min-Max\"\n",
    "            scaled = min_max_scale(col_data)\n",
    "        else:\n",
    "            method = \"Log + Standardization\"\n",
    "            scaled = standard_scale(log_transform(col_data))\n",
    "        \n",
    "        # Update scaled data\n",
    "        scaled_data[:, idx] = np.char.mod('%.6f', scaled)\n",
    "        scaling_methods[col] = method\n",
    "        \n",
    "        print(f\"{col:<30} {skew:<12.3f} {method:<20}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2f401",
   "metadata": {},
   "source": [
    "# **10. Encoding Categorical Variables - One-Hot Encoding**\n",
    "Chuyển đổi categorical features thành numerical format bằng One-Hot Encoding thủ công.\n",
    "\n",
    "**Ví dụ:** `Gender` (M, F) → `Gender_M` (0/1), `Gender_F` (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7c3476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE-HOT ENCODING CHO CATEGORICAL VARIABLES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender:\n",
      "  Categories: ['F' 'M']\n",
      "  Encoded shape: (10127, 2)\n",
      "  New column names: ['Gender_F', 'Gender_M']\n",
      "\n",
      "Education_Level:\n",
      "  Categories: ['College' 'Doctorate' 'Graduate' 'High School' 'Post-Graduate' 'Uneducated']\n",
      "  Encoded shape: (10127, 6)\n",
      "  New column names: ['Education_Level_College', 'Education_Level_Doctorate', 'Education_Level_Graduate', 'Education_Level_High School', 'Education_Level_Post-Graduate', 'Education_Level_Uneducated']\n",
      "\n",
      "Marital_Status:\n",
      "  Categories: ['Divorced' 'Married' 'Single']\n",
      "  Encoded shape: (10127, 3)\n",
      "  New column names: ['Marital_Status_Divorced', 'Marital_Status_Married', 'Marital_Status_Single']\n",
      "\n",
      "Income_Category:\n",
      "  Categories: ['$120K +' '$40K - $60K' '$60K - $80K' '$80K - $120K' 'Less than $40K']\n",
      "  Encoded shape: (10127, 5)\n",
      "  New column names: ['Income_Category_$120K +', 'Income_Category_$40K - $60K', 'Income_Category_$60K - $80K', 'Income_Category_$80K - $120K', 'Income_Category_Less than $40K']\n",
      "\n",
      "Card_Category:\n",
      "  Categories: ['Blue' 'Gold' 'Platinum' 'Silver']\n",
      "  Encoded shape: (10127, 4)\n",
      "  New column names: ['Card_Category_Blue', 'Card_Category_Gold', 'Card_Category_Platinum', 'Card_Category_Silver']\n",
      "\n",
      "================================================================================\n",
      "Encode 5 categorical columns\n",
      "Tổng số encoded features: 20\n",
      "================================================================================\n",
      "\n",
      "Education_Level:\n",
      "  Categories: ['College' 'Doctorate' 'Graduate' 'High School' 'Post-Graduate' 'Uneducated']\n",
      "  Encoded shape: (10127, 6)\n",
      "  New column names: ['Education_Level_College', 'Education_Level_Doctorate', 'Education_Level_Graduate', 'Education_Level_High School', 'Education_Level_Post-Graduate', 'Education_Level_Uneducated']\n",
      "\n",
      "Marital_Status:\n",
      "  Categories: ['Divorced' 'Married' 'Single']\n",
      "  Encoded shape: (10127, 3)\n",
      "  New column names: ['Marital_Status_Divorced', 'Marital_Status_Married', 'Marital_Status_Single']\n",
      "\n",
      "Income_Category:\n",
      "  Categories: ['$120K +' '$40K - $60K' '$60K - $80K' '$80K - $120K' 'Less than $40K']\n",
      "  Encoded shape: (10127, 5)\n",
      "  New column names: ['Income_Category_$120K +', 'Income_Category_$40K - $60K', 'Income_Category_$60K - $80K', 'Income_Category_$80K - $120K', 'Income_Category_Less than $40K']\n",
      "\n",
      "Card_Category:\n",
      "  Categories: ['Blue' 'Gold' 'Platinum' 'Silver']\n",
      "  Encoded shape: (10127, 4)\n",
      "  New column names: ['Card_Category_Blue', 'Card_Category_Gold', 'Card_Category_Platinum', 'Card_Category_Silver']\n",
      "\n",
      "================================================================================\n",
      "Encode 5 categorical columns\n",
      "Tổng số encoded features: 20\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ONE-HOT ENCODING CHO CATEGORICAL VARIABLES\")\n",
    " \n",
    "\n",
    "# Categorical columns cần encode\n",
    "_ , categorical_cols = feature_typing(col_names , data)\n",
    "categorical_cols = [col for col in categorical_cols if col != \"Attrition_Flag\"]\n",
    "\n",
    "encoded_features = []\n",
    "encoded_col_names = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in col_names:\n",
    "        idx = col_names.index(col)\n",
    "        col_data = scaled_data[:, idx]\n",
    "        \n",
    "        # One-hot encoding\n",
    "        encoded_matrix, categories = one_hot_encode_manual(col_data)\n",
    "        \n",
    "        # Tạo tên cho các encoded columns\n",
    "        new_names = [f\"{col}_{cat}\" for cat in categories]\n",
    "        \n",
    "        encoded_features.append(encoded_matrix)\n",
    "        encoded_col_names.extend(new_names)\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Categories: {categories}\")\n",
    "        print(f\"  Encoded shape: {encoded_matrix.shape}\")\n",
    "        print(f\"  New column names: {new_names}\")\n",
    "\n",
    "# Combine tất cả encoded features\n",
    "all_encoded = np.hstack(encoded_features)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Encode {len(categorical_cols)} categorical columns\")\n",
    "print(f\"Tổng số encoded features: {all_encoded.shape[1]}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebbd2a8",
   "metadata": {},
   "source": [
    "# **11. Kiểm định Giả thiết Thống kê (Hypothesis Testing)**\n",
    "Sử dụng **Z-test** (cho mẫu lớn) để kiểm định sự khác biệt giữa hai nhóm khách hàng.\n",
    "\n",
    "**Bài toán:** So sánh Hạn mức tín dụng trung bình (`Credit_Limit`) giữa Khách hàng Nam và Nữ.\n",
    "\n",
    "* **Giả thiết $H_0$:** $\\mu_{Male} = \\mu_{Female}$ (Không có sự khác biệt).\n",
    "* **Giả thiết $H_1$:** $\\mu_{Male} \\neq \\mu_{Female}$ (Có sự khác biệt).\n",
    "* **Mức ý nghĩa $\\alpha$:** 0.05.\n",
    "\n",
    "Công thức Z-statistic:\n",
    "$$Z = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26eb6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nam (M): n=4769, mean=12685.67, std=10647.94\n",
      "Nữ  (F): n=5358, mean=5023.85, std=5251.88\n",
      "\n",
      "Z-statistic: 45.0524\n",
      "Kết quả: |45.05| > 1.96 => Bác bỏ H0.\n",
      "Kết luận: Có sự khác biệt có ý nghĩa thống kê về hạn mức tín dụng giữa Nam và Nữ.\n"
     ]
    }
   ],
   "source": [
    "# 1. Tách nhóm dữ liệu\n",
    "idx_gen = col_names.index(\"Gender\")\n",
    "idx_lim = col_names.index(\"Credit_Limit\")\n",
    "\n",
    "# Lấy dữ liệu Credit Limit (đã clean ở bước Outlier) và ép kiểu float\n",
    "group_m = data[data[:, idx_gen] == \"M\", idx_lim].astype(float)\n",
    "group_f = data[data[:, idx_gen] == \"F\", idx_lim].astype(float)\n",
    "\n",
    "# 2. Tính toán các chỉ số thống kê\n",
    "n1, n2 = len(group_m), len(group_f)\n",
    "mean1, mean2 = np.mean(group_m), np.mean(group_f)\n",
    "# ddof=1 để tính độ lệch chuẩn mẫu (sample standard deviation)\n",
    "std1, std2 = np.std(group_m, ddof=1), np.std(group_f, ddof=1)\n",
    "\n",
    "print(f\"Nam (M): n={n1}, mean={mean1:.2f}, std={std1:.2f}\")\n",
    "print(f\"Nữ  (F): n={n2}, mean={mean2:.2f}, std={std2:.2f}\")\n",
    "\n",
    "# 3. Tính Z-score\n",
    "numerator = mean1 - mean2\n",
    "denominator = np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "z_stat = numerator / denominator\n",
    "\n",
    "print(f\"\\nZ-statistic: {z_stat:.4f}\")\n",
    "\n",
    "# 4. Kết luận\n",
    "# Với alpha = 0.05 (2 phía), ngưỡng tới hạn (Critical Value) là 1.96\n",
    "critical_val = 1.96\n",
    "\n",
    "if abs(z_stat) > critical_val:\n",
    "    print(f\"Kết quả: |{z_stat:.2f}| > {critical_val} => Bác bỏ H0.\")\n",
    "    print(\"Kết luận: Có sự khác biệt có ý nghĩa thống kê về hạn mức tín dụng giữa Nam và Nữ.\")\n",
    "else:\n",
    "    print(f\"Kết quả: |{z_stat:.2f}| <= {critical_val} => Không đủ cơ sở bác bỏ H0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24380125",
   "metadata": {},
   "source": [
    "# **12. Kiểm định Giả thiết - Chi-Square Test**\n",
    "**Bài toán:** Kiểm định mối quan hệ giữa `Card_Category` và `Attrition_Flag`.\n",
    "\n",
    "* **Giả thiết $H_0$:** Card Category và Attrition độc lập với nhau.\n",
    "* **Giả thiết $H_1$:** Card Category và Attrition có liên hệ với nhau.\n",
    "* **Mức ý nghĩa $\\alpha$:** 0.05.\n",
    "\n",
    "**Công thức Chi-square:**\n",
    "$$\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$\n",
    "\n",
    "với $E_{ij} = \\frac{\\text{Row}_i \\times \\text{Col}_j}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce730850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHI-SQUARE TEST: CARD CATEGORY vs ATTRITION\n",
      "\n",
      "Contingency Table:\n",
      "Card Category  Attrited Customer   Existing Customer   Total\n",
      "----------------------------------------------------------------------\n",
      "Blue           1519                7917                9436\n",
      "Gold           21                  95                  116\n",
      "Platinum       5                   15                  20\n",
      "Silver         82                  473                 555\n",
      "\n",
      "Kiểm định giả thiết:\n",
      "   H0: Card Category và Attrition độc lập\n",
      "   H1: Card Category và Attrition có liên hệ\n",
      "   Significance level: α = 0.05\n",
      "\n",
      "Kết quả:\n",
      "   Chi-square statistic: 2.2342\n",
      "   Degrees of freedom: 3\n",
      "   P-value (approx): 0.525301\n",
      "\n",
      "Kết luận: KHÔNG ĐỦ CƠ SỞ BÁC BỎ H0 (p=0.525301 >= 0.05)\n",
      "   → Chưa có bằng chứng cho thấy có liên hệ\n"
     ]
    }
   ],
   "source": [
    "print(\"CHI-SQUARE TEST: CARD CATEGORY vs ATTRITION\")\n",
    " \n",
    "\n",
    "# 1. Tạo Contingency Table\n",
    "idx_card = col_names.index(\"Card_Category\")\n",
    "idx_attr = col_names.index(\"Attrition_Flag\")\n",
    "\n",
    "card_categories = np.unique(data[:, idx_card])\n",
    "attrition_statuses = np.unique(data[:, idx_attr])\n",
    "\n",
    "# Build contingency table\n",
    "contingency_table = []\n",
    "for card in card_categories:\n",
    "    row = []\n",
    "    for attr in attrition_statuses:\n",
    "        count = np.sum((data[:, idx_card] == card) & (data[:, idx_attr] == attr))\n",
    "        row.append(count)\n",
    "    contingency_table.append(row)\n",
    "\n",
    "contingency_table = np.array(contingency_table)\n",
    "\n",
    "print(\"\\nContingency Table:\")\n",
    "print(f\"{'Card Category':<15}\", end=\"\")\n",
    "for attr in attrition_statuses:\n",
    "    print(f\"{attr:<20}\", end=\"\")\n",
    "print(\"Total\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, card in enumerate(card_categories):\n",
    "    print(f\"{card:<15}\", end=\"\")\n",
    "    row_sum = 0\n",
    "    for j in range(len(attrition_statuses)):\n",
    "        print(f\"{contingency_table[i, j]:<20}\", end=\"\")\n",
    "        row_sum += contingency_table[i, j]\n",
    "    print(row_sum)\n",
    "\n",
    "# 2. Chi-square test\n",
    "chi2, p_value, df, expected = chi_square_test_manual(contingency_table)\n",
    "\n",
    "print(f\"\\nKiểm định giả thiết:\")\n",
    "print(f\"   H0: Card Category và Attrition độc lập\")\n",
    "print(f\"   H1: Card Category và Attrition có liên hệ\")\n",
    "print(f\"   Significance level: α = 0.05\")\n",
    "print(f\"\\nKết quả:\")\n",
    "print(f\"   Chi-square statistic: {chi2:.4f}\")\n",
    "print(f\"   Degrees of freedom: {df}\")\n",
    "print(f\"   P-value (approx): {p_value:.6f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(f\"\\nKết luận: BÁC BỎ H0 (p={p_value:.6f} < 0.05)\")\n",
    "    print(\"   → Card Category và Attrition CÓ LIÊN HỆ có ý nghĩa thống kê\")\n",
    "else:\n",
    "    print(f\"\\nKết luận: KHÔNG ĐỦ CƠ SỞ BÁC BỎ H0 (p={p_value:.6f} >= 0.05)\")\n",
    "    print(\"   → Chưa có bằng chứng cho thấy có liên hệ\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08d56d",
   "metadata": {},
   "source": [
    "# **13. Kiểm định Giả thiết - Independent T-Test**\n",
    "**Bài toán:** So sánh Transaction Amount trung bình giữa Existing vs Attrited customers.\n",
    "\n",
    "* **Giả thiết $H_0$:** $\\mu_{Existing} = \\mu_{Attrited}$.\n",
    "* **Giả thiết $H_1$:** $\\mu_{Existing} \\neq \\mu_{Attrited}$.\n",
    "* **Mức ý nghĩa $\\alpha$:** 0.05.\n",
    "\n",
    "**Công thức t-statistic:**\n",
    "$$t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8894470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEPENDENT T-TEST: TRANSACTION AMOUNT - EXISTING vs ATTRITED\n",
      "\n",
      "Existing Customers:\n",
      "  n = 8500\n",
      "  Mean = 4612.85\n",
      "  Std = 3383.19\n",
      "\n",
      "Attrited Customers:\n",
      "  n = 1627\n",
      "  Mean = 3095.03\n",
      "  Std = 2308.23\n",
      "\n",
      "Kiểm định giả thiết:\n",
      "   H0: μ_Existing = μ_Attrited\n",
      "   H1: μ_Existing ≠ μ_Attrited\n",
      "   Significance level: α = 0.05\n",
      "\n",
      "Kết quả:\n",
      "   t-statistic: 22.3276\n",
      "   Degrees of freedom: 3136.72\n",
      "   P-value (two-tailed): 0.0000000000\n",
      "\n",
      "Kết luận: BÁC BỎ H0 (p=0.0000000000 < 0.05)\n",
      "   → Có sự khác biệt CÓ Ý NGHĨA THỐNG KÊ về Transaction Amount\n",
      "   → Existing customers có trung bình cao hơn 1517.83\n"
     ]
    }
   ],
   "source": [
    "print(\"INDEPENDENT T-TEST: TRANSACTION AMOUNT - EXISTING vs ATTRITED\")\n",
    " \n",
    "# 1. Phân nhóm dữ liệu\n",
    "idx_attr = col_names.index(\"Attrition_Flag\")\n",
    "idx_trans_amt = col_names.index(\"Total_Trans_Amt\")\n",
    "\n",
    "existing_mask = (data[:, idx_attr] == \"Existing Customer\")\n",
    "attrited_mask = (data[:, idx_attr] == \"Attrited Customer\")\n",
    "\n",
    "trans_existing = data[existing_mask, idx_trans_amt].astype(float)\n",
    "trans_attrited = data[attrited_mask, idx_trans_amt].astype(float)\n",
    "\n",
    "# 2. Thống kê mô tả\n",
    "print(f\"\\nExisting Customers:\")\n",
    "print(f\"  n = {len(trans_existing)}\")\n",
    "print(f\"  Mean = {np.mean(trans_existing):.2f}\")\n",
    "print(f\"  Std = {np.std(trans_existing, ddof=1):.2f}\")\n",
    "\n",
    "print(f\"\\nAttrited Customers:\")\n",
    "print(f\"  n = {len(trans_attrited)}\")\n",
    "print(f\"  Mean = {np.mean(trans_attrited):.2f}\")\n",
    "print(f\"  Std = {np.std(trans_attrited, ddof=1):.2f}\")\n",
    "\n",
    "# 3. T-test\n",
    "t_stat, p_value, df = t_test_independent_manual(trans_existing, trans_attrited)\n",
    "\n",
    "print(f\"\\nKiểm định giả thiết:\")\n",
    "print(f\"   H0: μ_Existing = μ_Attrited\")\n",
    "print(f\"   H1: μ_Existing ≠ μ_Attrited\")\n",
    "print(f\"   Significance level: α = 0.05\")\n",
    "print(f\"\\nKết quả:\")\n",
    "print(f\"   t-statistic: {t_stat:.4f}\")\n",
    "print(f\"   Degrees of freedom: {df:.2f}\")\n",
    "print(f\"   P-value (two-tailed): {p_value:.10f}\")\n",
    "\n",
    "# Critical value cho α=0.05, two-tailed (approx 1.96 for large df)\n",
    "if p_value < 0.05:\n",
    "    print(f\"\\nKết luận: BÁC BỎ H0 (p={p_value:.10f} < 0.05)\")\n",
    "    print(\"   → Có sự khác biệt CÓ Ý NGHĨA THỐNG KÊ về Transaction Amount\")\n",
    "    diff = np.mean(trans_existing) - np.mean(trans_attrited)\n",
    "    print(f\"   → Existing customers có trung bình cao hơn {diff:.2f}\")\n",
    "else:\n",
    "    print(f\"\\nKết luận: KHÔNG ĐỦ CƠ SỞ BÁC BỎ H0 (p={p_value:.6f} >= 0.05)\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dd68b",
   "metadata": {},
   "source": [
    "# **14. Tạo Final Preprocessed Dataset và Lưu File**\n",
    "Kết hợp tất cả:\n",
    "1. Numerical features (đã scaled)\n",
    "2. Engineered features\n",
    "3. Encoded categorical features\n",
    "4. Target variable\n",
    "\n",
    "Sau đó lưu vào file `.npy` để sử dụng cho modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77f6ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TẠO FINAL PREPROCESSED DATASET\n",
      "\n",
      "1. Numerical features (scaled): (10127, 20)\n",
      "2. Categorical features (encoded): (10127, 20)\n",
      "3. Combined features: (10127, 40)\n",
      "4. Target variable: (10127,)\n",
      "   - Class 0 (Existing): 8500 samples\n",
      "   - Class 1 (Attrited): 1627 samples\n",
      "\n",
      "Đã lưu preprocessed data vào: ../data/processed/\n",
      "   - X_preprocessed.npy\n",
      "   - y_target.npy\n",
      "   - feature_names.txt\n",
      "   - preprocessing_metadata.txt\n",
      "\n",
      "1. Numerical features (scaled): (10127, 20)\n",
      "2. Categorical features (encoded): (10127, 20)\n",
      "3. Combined features: (10127, 40)\n",
      "4. Target variable: (10127,)\n",
      "   - Class 0 (Existing): 8500 samples\n",
      "   - Class 1 (Attrited): 1627 samples\n",
      "\n",
      "Đã lưu preprocessed data vào: ../data/processed/\n",
      "   - X_preprocessed.npy\n",
      "   - y_target.npy\n",
      "   - feature_names.txt\n",
      "   - preprocessing_metadata.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"TẠO FINAL PREPROCESSED DATASET\")\n",
    " \n",
    "\n",
    "# 1. Lấy numerical features (đã scaled)\n",
    "numerical_indices = [col_names.index(col) for col in numerical_cols_to_scale if col in col_names]\n",
    "X_numerical = scaled_data[:, numerical_indices].astype(float)\n",
    "\n",
    "print(f\"\\n1. Numerical features (scaled): {X_numerical.shape}\")\n",
    "\n",
    "# 2. Lấy encoded categorical features\n",
    "X_categorical = all_encoded\n",
    "\n",
    "print(f\"2. Categorical features (encoded): {X_categorical.shape}\")\n",
    "\n",
    "# 3. Combine tất cả features\n",
    "X_final = np.hstack([X_numerical, X_categorical])\n",
    "\n",
    "# 4. Target variable\n",
    "idx_target = col_names.index(\"Attrition_Flag\")\n",
    "y = np.array([1 if val == \"Attrited Customer\" else 0 for val in data[:, idx_target]])\n",
    "\n",
    "print(f\"3. Combined features: {X_final.shape}\")\n",
    "print(f\"4. Target variable: {y.shape}\")\n",
    "print(f\"   - Class 0 (Existing): {np.sum(y==0)} samples\")\n",
    "print(f\"   - Class 1 (Attrited): {np.sum(y==1)} samples\")\n",
    "\n",
    "# 5. Lưu vào file\n",
    "import os\n",
    "\n",
    "output_dir = \"../data/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Lưu features và target\n",
    "np.save(os.path.join(output_dir, \"X_preprocessed.npy\"), X_final)\n",
    "np.save(os.path.join(output_dir, \"y_target.npy\"), y)\n",
    "\n",
    "# Lưu feature names\n",
    "all_final_feature_names = [col for col in numerical_cols_to_scale if col in col_names] + encoded_col_names\n",
    "\n",
    "with open(os.path.join(output_dir, \"feature_names.txt\"), \"w\") as f:\n",
    "    for fname in all_final_feature_names:\n",
    "        f.write(fname + \"\\n\")\n",
    "\n",
    "# Lưu metadata\n",
    "with open(os.path.join(output_dir, \"preprocessing_metadata.txt\"), \"w\") as f:\n",
    "    f.write(\"PREPROCESSING METADATA\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Dataset shape: {X_final.shape}\\n\")\n",
    "    f.write(f\"Number of samples: {X_final.shape[0]}\\n\")\n",
    "    f.write(f\"Number of features: {X_final.shape[1]}\\n\")\n",
    "    f.write(f\"  - Numerical (scaled): {X_numerical.shape[1]}\\n\")\n",
    "    f.write(f\"  - Categorical (encoded): {X_categorical.shape[1]}\\n\\n\")\n",
    "    f.write(f\"Target distribution:\\n\")\n",
    "    f.write(f\"  - Class 0 (Existing): {np.sum(y==0)} ({np.sum(y==0)/len(y)*100:.2f}%)\\n\")\n",
    "    f.write(f\"  - Class 1 (Attrited): {np.sum(y==1)} ({np.sum(y==1)/len(y)*100:.2f}%)\\n\\n\")\n",
    "    f.write(\"Scaling methods applied:\\n\")\n",
    "    for col, method in scaling_methods.items():\n",
    "        f.write(f\"  - {col}: {method}\\n\")\n",
    "\n",
    "print(f\"\\nĐã lưu preprocessed data vào: {output_dir}/\")\n",
    "print(f\"   - X_preprocessed.npy\")\n",
    "print(f\"   - y_target.npy\")\n",
    "print(f\"   - feature_names.txt\")\n",
    "print(f\"   - preprocessing_metadata.txt\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
